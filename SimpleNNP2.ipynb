{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゼロから始める簡単NNP (対称性関数のチューニング)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNPとは？？\n",
    "Neural Network Potentialの略です。原子構造の情報を受け取って、エネルギーの値を予測する、ニューラルネットワークベースの機械学習モデルです。第一原理計算での構造とエネルギーの関係を再現するように、第一原理計算結果を使って学習させる仕組みを使っています。\n",
    "\n",
    "この最も単純なケースを試してみましょう。今回扱うのは、結晶Siです。分子動力学法のトラジェクトリーを使って、様々な温度での熱ゆらぎが加わっていたり、密度が異なった状態での1250パターンの構造とエネルギーの情報を集めてあるので、それを学習データにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対称性関数の計算結果のロード\n",
    "構造とエネルギーの関係を学ばせるにあたって、まず構造をニューラルネットワーク的に扱いやすいデータに変換する必要があります。\n",
    "その方法の一つが対称性関数です。ここでは、対称性関数のパラメータをある程度調整した場合の計算結果を使います。\n",
    "\n",
    "対称性関数の説明や計算は別のファイルにまとめているので、そちらを見てください。\n",
    "https://github.com/eminamitani/sample_NNP/blob/main/make_desc_large.ipynb\n",
    "\n",
    "今回は時間短縮のため保存しておいたデータを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "desc=np.load('desc_large2.npy')\n",
    "label=np.load('label_large2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 64, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データがどんな形か確認してみましょう。descは計算された対称性関数の11の値（最初の値は、G0と表記されるシンプルな動径分布に対応します）を保持していて、labelは系の原子あたりの平均エネルギーの情報を持っています。(全エネルギーそのままだと値が大きすぎるので)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.26244   , 6.5645013 , 6.8478737 , 7.095261  , 7.46383   ,\n",
       "        7.6411366 , 7.6528153 , 7.52056   , 3.758342  , 4.1961546 ,\n",
       "        4.607235  , 5.321424  , 5.817775  , 5.9414434 , 5.845667  ,\n",
       "        8.36925   , 6.6050043 , 4.6383796 , 3.104257  , 1.3400111 ,\n",
       "        0.42756554, 0.34005523, 0.2741888 , 0.20551518, 0.1318433 ,\n",
       "        0.06597685, 0.02572226], dtype=float32),\n",
       " -5.8122244)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[0,0,:], label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.022465  ,  7.311376  ,  7.601747  ,  7.8504934 ,  8.204621  ,\n",
       "         8.345448  ,  8.331387  ,  8.135118  ,  4.291214  ,  4.750723  ,\n",
       "         5.1840878 ,  5.9365387 ,  6.427783  ,  6.518643  ,  6.290091  ,\n",
       "        10.702587  ,  8.349539  ,  5.7685575 ,  4.206671  ,  1.8536228 ,\n",
       "         0.6094486 ,  0.51270366,  0.40338242,  0.2943864 ,  0.22587003,\n",
       "         0.1165488 ,  0.04624842], dtype=float32),\n",
       " -5.812823)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[1,0,:], label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対称性関数の値にもそれなりにばらつきがありそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの実装では配列の形を勘違いしてミスをすることが多いので確認しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 64, 27), (1250,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本当はデータを正規化したほうが良いのですが、ひとまず単純に処理してみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ニューラルネットワークの定義\n",
    " 今回は、ニューラルネットワークというと真っ先にイメージされる多層パーセプトロンを使います。\n",
    "\n",
    " このモデルでは、11の対称性関数の値を受け取って、それをノード数20の隠れ層に渡し、最終的に一つの出力を得る形になっています。\n",
    " この出力は「原子ひとつあたりのエネルギー」に相当すると考えます。原子ひとつあたりのエネルギーがきちんと定義できるのかはさておき、それらを足し上げると、系の全エネルギーになるようにネットワーク中の重みやバイアスを最適化していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    #n_sf : number of symmetry function\n",
    "    #two-hidden layer\n",
    "    #output is energy per atom\n",
    "    def __init__(self,n_sf,n_hidden):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(n_sf, n_hidden)\n",
    "        self.a1  = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.a2  = nn.Tanh()\n",
    "        self.fc3 = nn.Linear(n_hidden,1)\n",
    "\n",
    "        #for debug backprop\n",
    "        self.fc1mask=[]\n",
    "        self.fc2mask=[]\n",
    "\n",
    "        #He initialization\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        self.results={}\n",
    "\n",
    "        self.layers=[self.fc1, self.a1, self.fc2, self.a2, self.fc3]\n",
    "\n",
    "    #relu actination function\n",
    "    #two hidden layer\n",
    "    #evaluate eneergy & derivative in forward run\n",
    "    def forward(self,x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x=layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データとテストデータの分割\n",
    "機械学習では過学習（使ったデータにはよく合うが、それ以外のデータにはうまく対応できない）がつきものなので、汎化性能を調べるために、学習データとテストデータの分割を行います。今回は8割を学習データ、2割をテストデータにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(desc, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorchはテンソルを入力として受け取り、出力もテンソルにすることができます。上記の`Net`クラスで実装されているモデルはベクトルを受け取ることを前提にかかれていますが、それが積み上がってテンソルになった入力に対しても柔軟に処理することができます。イメージ的に分かりにくいので、実際にやってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 64, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ処理の概要確認\n",
    "#テンソルとしてデータを一気に流し込み、原子数の次元で和を取る\n",
    "nacsf=33\n",
    "model=Net(n_sf=nacsf,n_hidden=100)\n",
    "test_out=model(torch.tensor(X_train))\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000データがあって、それぞれに（64,1）の配列が格納されている形式になっています。この64というのは原子数で、実際の正解データと比較するのは、64原子分の総和をとった値です。それは以下のようにして計算できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_energy=torch.sum(test_out, dim=1)\n",
    "p_energy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データローダーの定義\n",
    "効率よく学習させるためにはミニバッチ学習が欠かせません。というわけで、そのためのデータローダーを組みます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchのtensor型に変換します。y_train, y_testはモデルの出力と整合させるために、unsqueeze(1)で余分な次元をつけています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(X_train)\n",
    "X_test=torch.tensor(X_test)\n",
    "y_train=torch.tensor(y_train).unsqueeze(1)\n",
    "y_test=torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "train_dset=[(data,label) for data, label in zip(X_train, y_train)]\n",
    "test_dset=[(data,label) for data, label in zip(X_test, y_test)]\n",
    "nbatch=100\n",
    "train_loader =torch.utils.data.DataLoader(train_dset, batch_size=nbatch, shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dset, batch_size=nbatch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習部分のコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import datetime\n",
    "dir=os.path.join(\"./logs\", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "writer = SummaryWriter(log_dir=dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習＆テスト結果のループ部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, test_loader,scheduler,device):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_t=0.0\n",
    "        loss_v=0.0\n",
    "        for train, train_labels in train_loader:\n",
    "            train=train.to(device)\n",
    "            train_labels=train_labels.to(device)\n",
    "            tmp=model(train)\n",
    "            p_train=torch.sum(tmp, dim=1)/64.0\n",
    "\n",
    "            loss_train=loss_fn(p_train, train_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            loss_t+=loss_train.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        #validation\n",
    "        with torch.no_grad():\n",
    "            for val, val_labels in test_loader:\n",
    "                val=val.to(device)\n",
    "                val_labels=val_labels.to(device)\n",
    "                p_val= torch.sum(model(val),dim=1)/64.0\n",
    "                loss_val=loss_fn(p_val, val_labels)\n",
    "                loss_v+=loss_val.item()\n",
    "        \n",
    "        writer.add_scalar(\"loss_train\", loss_t/len(train_loader), epoch)  \n",
    "        writer.add_scalar(\"loss_val\", loss_v/len(test_loader), epoch)  \n",
    "        \n",
    "        if epoch == 1 or epoch %100 ==0:\n",
    "            print('Epoch %d, Training Loss %f' %(epoch, loss_t/len(train_loader)))\n",
    "            print('\\t Validation Loss %f' %(loss_v/len(test_loader)))\n",
    "    \n",
    "    writer.close()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータの更新はAdamで行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "scheduler = MultiStepLR(optimizer, milestones=[2000,4000,6000],gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss 22.127631\n",
      "\t Validation Loss 15.859093\n",
      "Epoch 100, Training Loss 0.003443\n",
      "\t Validation Loss 0.003754\n",
      "Epoch 200, Training Loss 0.003397\n",
      "\t Validation Loss 0.003672\n",
      "Epoch 300, Training Loss 0.003301\n",
      "\t Validation Loss 0.003540\n",
      "Epoch 400, Training Loss 0.003014\n",
      "\t Validation Loss 0.003180\n",
      "Epoch 500, Training Loss 0.001737\n",
      "\t Validation Loss 0.001955\n",
      "Epoch 600, Training Loss 0.000497\n",
      "\t Validation Loss 0.000916\n",
      "Epoch 700, Training Loss 0.000470\n",
      "\t Validation Loss 0.000396\n",
      "Epoch 800, Training Loss 0.000302\n",
      "\t Validation Loss 0.000352\n",
      "Epoch 900, Training Loss 0.000296\n",
      "\t Validation Loss 0.000524\n",
      "Epoch 1000, Training Loss 0.000290\n",
      "\t Validation Loss 0.000330\n",
      "Epoch 1100, Training Loss 0.000323\n",
      "\t Validation Loss 0.000384\n",
      "Epoch 1200, Training Loss 0.000364\n",
      "\t Validation Loss 0.000731\n",
      "Epoch 1300, Training Loss 0.000230\n",
      "\t Validation Loss 0.000463\n",
      "Epoch 1400, Training Loss 0.000380\n",
      "\t Validation Loss 0.000321\n",
      "Epoch 1500, Training Loss 0.000240\n",
      "\t Validation Loss 0.000432\n",
      "Epoch 1600, Training Loss 0.000236\n",
      "\t Validation Loss 0.000348\n",
      "Epoch 1700, Training Loss 0.000230\n",
      "\t Validation Loss 0.000609\n",
      "Epoch 1800, Training Loss 0.000271\n",
      "\t Validation Loss 0.000539\n",
      "Epoch 1900, Training Loss 0.000302\n",
      "\t Validation Loss 0.000313\n",
      "Epoch 2000, Training Loss 0.000236\n",
      "\t Validation Loss 0.000267\n",
      "Epoch 2100, Training Loss 0.000169\n",
      "\t Validation Loss 0.000230\n",
      "Epoch 2200, Training Loss 0.000160\n",
      "\t Validation Loss 0.000230\n",
      "Epoch 2300, Training Loss 0.000170\n",
      "\t Validation Loss 0.000213\n",
      "Epoch 2400, Training Loss 0.000151\n",
      "\t Validation Loss 0.000193\n",
      "Epoch 2500, Training Loss 0.000132\n",
      "\t Validation Loss 0.000188\n",
      "Epoch 2600, Training Loss 0.000133\n",
      "\t Validation Loss 0.000186\n",
      "Epoch 2700, Training Loss 0.000146\n",
      "\t Validation Loss 0.000194\n",
      "Epoch 2800, Training Loss 0.000167\n",
      "\t Validation Loss 0.000169\n",
      "Epoch 2900, Training Loss 0.000122\n",
      "\t Validation Loss 0.000174\n",
      "Epoch 3000, Training Loss 0.000119\n",
      "\t Validation Loss 0.000145\n",
      "Epoch 3100, Training Loss 0.000130\n",
      "\t Validation Loss 0.000183\n",
      "Epoch 3200, Training Loss 0.000124\n",
      "\t Validation Loss 0.000218\n",
      "Epoch 3300, Training Loss 0.000120\n",
      "\t Validation Loss 0.000155\n",
      "Epoch 3400, Training Loss 0.000110\n",
      "\t Validation Loss 0.000135\n",
      "Epoch 3500, Training Loss 0.000145\n",
      "\t Validation Loss 0.000186\n",
      "Epoch 3600, Training Loss 0.000152\n",
      "\t Validation Loss 0.000138\n",
      "Epoch 3700, Training Loss 0.000113\n",
      "\t Validation Loss 0.000139\n",
      "Epoch 3800, Training Loss 0.000108\n",
      "\t Validation Loss 0.000142\n",
      "Epoch 3900, Training Loss 0.000118\n",
      "\t Validation Loss 0.000123\n",
      "Epoch 4000, Training Loss 0.000129\n",
      "\t Validation Loss 0.000130\n",
      "Epoch 4100, Training Loss 0.000104\n",
      "\t Validation Loss 0.000141\n",
      "Epoch 4200, Training Loss 0.000108\n",
      "\t Validation Loss 0.000145\n",
      "Epoch 4300, Training Loss 0.000101\n",
      "\t Validation Loss 0.000123\n",
      "Epoch 4400, Training Loss 0.000107\n",
      "\t Validation Loss 0.000187\n",
      "Epoch 4500, Training Loss 0.000101\n",
      "\t Validation Loss 0.000118\n",
      "Epoch 4600, Training Loss 0.000097\n",
      "\t Validation Loss 0.000127\n",
      "Epoch 4700, Training Loss 0.000115\n",
      "\t Validation Loss 0.000158\n",
      "Epoch 4800, Training Loss 0.000115\n",
      "\t Validation Loss 0.000124\n",
      "Epoch 4900, Training Loss 0.000101\n",
      "\t Validation Loss 0.000122\n",
      "Epoch 5000, Training Loss 0.000099\n",
      "\t Validation Loss 0.000121\n",
      "Epoch 5100, Training Loss 0.000100\n",
      "\t Validation Loss 0.000122\n",
      "Epoch 5200, Training Loss 0.000105\n",
      "\t Validation Loss 0.000137\n",
      "Epoch 5300, Training Loss 0.000096\n",
      "\t Validation Loss 0.000126\n",
      "Epoch 5400, Training Loss 0.000107\n",
      "\t Validation Loss 0.000199\n",
      "Epoch 5500, Training Loss 0.000114\n",
      "\t Validation Loss 0.000124\n",
      "Epoch 5600, Training Loss 0.000099\n",
      "\t Validation Loss 0.000135\n",
      "Epoch 5700, Training Loss 0.000101\n",
      "\t Validation Loss 0.000137\n",
      "Epoch 5800, Training Loss 0.000108\n",
      "\t Validation Loss 0.000118\n",
      "Epoch 5900, Training Loss 0.000094\n",
      "\t Validation Loss 0.000125\n",
      "Epoch 6000, Training Loss 0.000107\n",
      "\t Validation Loss 0.000148\n",
      "Epoch 6100, Training Loss 0.000099\n",
      "\t Validation Loss 0.000121\n",
      "Epoch 6200, Training Loss 0.000099\n",
      "\t Validation Loss 0.000128\n",
      "Epoch 6300, Training Loss 0.000098\n",
      "\t Validation Loss 0.000136\n",
      "Epoch 6400, Training Loss 0.000093\n",
      "\t Validation Loss 0.000135\n",
      "Epoch 6500, Training Loss 0.000103\n",
      "\t Validation Loss 0.000134\n",
      "Epoch 6600, Training Loss 0.000092\n",
      "\t Validation Loss 0.000121\n",
      "Epoch 6700, Training Loss 0.000092\n",
      "\t Validation Loss 0.000123\n",
      "Epoch 6800, Training Loss 0.000095\n",
      "\t Validation Loss 0.000121\n",
      "Epoch 6900, Training Loss 0.000094\n",
      "\t Validation Loss 0.000127\n",
      "Epoch 7000, Training Loss 0.000095\n",
      "\t Validation Loss 0.000122\n",
      "Epoch 7100, Training Loss 0.000100\n",
      "\t Validation Loss 0.000133\n",
      "Epoch 7200, Training Loss 0.000091\n",
      "\t Validation Loss 0.000126\n",
      "Epoch 7300, Training Loss 0.000106\n",
      "\t Validation Loss 0.000165\n",
      "Epoch 7400, Training Loss 0.000093\n",
      "\t Validation Loss 0.000117\n",
      "Epoch 7500, Training Loss 0.000092\n",
      "\t Validation Loss 0.000129\n",
      "Epoch 7600, Training Loss 0.000103\n",
      "\t Validation Loss 0.000124\n",
      "Epoch 7700, Training Loss 0.000097\n",
      "\t Validation Loss 0.000112\n",
      "Epoch 7800, Training Loss 0.000091\n",
      "\t Validation Loss 0.000117\n",
      "Epoch 7900, Training Loss 0.000094\n",
      "\t Validation Loss 0.000123\n",
      "Epoch 8000, Training Loss 0.000091\n",
      "\t Validation Loss 0.000118\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=8000, optimizer=optimizer,model=model,\n",
    "             loss_fn=nn.MSELoss(), train_loader=train_loader, test_loader=test_loader,scheduler=scheduler,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解と予測結果をプロットしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict=torch.sum(model(X_test.to(device)),dim=1)/64.0\n",
    "    train=torch.sum(model(X_train.to(device)),dim=1)/64.0\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlim((-6,-5.6))\n",
    "    plt.ylim((-6,-5.6))\n",
    "    \n",
    "    plt.scatter(y_train,train.to('cpu'),c='red',s=2,alpha=0.5,label='train')\n",
    "    plt.scatter(y_test,predict.to('cpu'),c='blue',s=2,alpha=0.5,label='test')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010806686"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=(y_test-predict.to('cpu').detach().numpy()).numpy()\n",
    "np.sqrt(np.mean(np.abs(diff)*np.abs(diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対称性関数のとり方を工夫することでだいぶ精度が向上していることがわかります"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb7935f57bbdef563505bbe55a73b776f504e7646c87521f5e2f2142831702de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('env_3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
